{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702ad69d",
   "metadata": {},
   "source": [
    "# <font color=\"#3A40A2\">📘 5. Combinando Aprendizaje No Supervisado y Aprendizaje Supervisado</font>\n",
    "\n",
    "**Materia: Ciencia de Datos aplicada a los Negocios - Universidad de San Andrés**\n",
    "\n",
    "**Autor: [Lucas BALDEZZARI](https://www.linkedin.com/in/lucasbaldezzari/)**\n",
    "\n",
    "**2025**\n",
    "\n",
    "> Este material es para fines educativos y no debe ser utilizado para fines comerciales. El contenido pertenece a la *Universidad de San Andrés* y no debe ser reproducido sin el permiso explícito de la institución y del autor de este repositorio quien es [LUCAS BALDEZZARI](https://www.linkedin.com/feed/).\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebbcc5",
   "metadata": {},
   "source": [
    "## <font color=\"#004eb3\">Temas de la Colab</font>\n",
    "\n",
    "- Para esta clase aplicaremos los conceptos vistos en las clases anteriores para combinar técnicas de Aprendizaje No Supervisado y Aprendizaje Supervisado. En particular, veremos cómo utilizar técnicas de reducción de dimensionalidad para mejorar el rendimiento de modelos supervisados.\n",
    "\n",
    "Es importante prestar atención a los siguientes íconos o emojis que aparezcan a lo largo de la Colab.\n",
    "\n",
    "- 📘 **Teoría**: Conceptos teóricos.\n",
    "- 📚 **Lectura**: Material adicional que puedes consultar para profundizar en el tema.\n",
    "- 📊 **Ejemplo**: Ejemplo para demostrar y/o reforzar conceptos.\n",
    "- 🔗 **Enlace**: Recursos externos que puedes visitar para obtener más información.\n",
    "- ❓ **Pregunta**: Preguntas disparadas a lo largo del contenido para reflexionar sobre los ejemplos y conceptos tratados.\n",
    "- 💻 **Código**: Indica que la celda de abajo es una celda con código y debe ser ejecutada para ver su contenido.\n",
    "- 📝 **Respuestas**: Respuestas a las preguntas planteadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e253dc4",
   "metadata": {},
   "source": [
    "### **<font color=\"#0205d6\">Integrantes del grupo</font>**\n",
    "\n",
    "Por favor, colocar los nombres de los/as integrantes del grupo que trabajó en esta Colab.\n",
    "- Integrante 1\n",
    "- Integrante 2\n",
    "- Integrante 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14fa59",
   "metadata": {},
   "source": [
    "💻 Por favor, ejecuta la celda de abajo para clonar el repositorio y poder trabajar 💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394192d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **** CÓDIGO PYTHON ****\n",
    "\n",
    "##Clonamos el repositorio para poder usar las funciones\n",
    "## Esperar unos segundos hasta ver un 100% de descarga\n",
    "# !git clone https://github.com/lucasbaldezzari/cdan.git\n",
    "\n",
    "##importamos las funciones a usar\n",
    "from funciones.combinations import *\n",
    "# from funciones.utils import * ##importo funciones a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d39d1",
   "metadata": {},
   "source": [
    "# 📊 **<font color=\"#d6b302\">1. LDA vs PCA para reducción de dimensionalidad y clasificación</font>**\n",
    "\n",
    "En este primer ejercicio vamos a usar LDA y PCA para reducir dimensiones y comparar la performance de un SVM en ambos casos.\n",
    "\n",
    "Usaremos el set de datos llamado *Wine*, donde puede obtenerse información del mismo en [Wine](https://archive.ics.uci.edu/dataset/109/wine) y [Wine recognition dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset) que contiene 13 features y 3 clases. El objetivo es predecir la clase a la que pertenece cada muestra.\n",
    "\n",
    "Este set de datos posee 178 muestras. Las características son resultados de análisis químicos de diferentes vinos. La variable objetivo es la clase del vino, que puede ser 1, 2 o 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e53dd4",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">📘 Repaso teórico 📘</font>\n",
    "\n",
    "- PCA realiza la reducción de dimensionalidad maximizando la varianza de los datos. En la mayoría de los casos, la **estandarización** de las características es necesaria antes de aplicar PCA.\n",
    "- LDA realiza la reducción de dimensionalidad maximizando la separabilidad de clases de los conjuntos de datos de clasificación.\n",
    "- PCA no requiere etiquetas de clase. Por esta razón, podemos usarlo con clasificación, regresión e incluso con datos no etiquetados.\n",
    "- LDA requiere etiquetas de clase. Por lo tanto, se utiliza con conjuntos de datos de clasificación.\n",
    "- PCA encuentra un conjunto de características no correlacionadas en un espacio de menor dimensión. Esto significa que las nuevas características (componentes principales) son combinaciones lineales de las características originales.\n",
    "- Como hemos visto, LDA se puede utilizar tanto para tareas supervisadas como no supervisadas. PCA solo se puede utilizar para la reducción de dimensionalidad no supervisada.\n",
    "- El número máximo de componentes que PCA puede encontrar es igual al número de características de entrada (dimensionalidad original) del conjunto de datos. Sin embargo, en general queremos encontrar un número más bajo de componentes que capture la mayor cantidad posible de la varianza en los datos originales.\n",
    "- El número máximo de componentes que LDA puede encontrar es igual al número de clases menos uno en el conjunto de datos de clasificación. Por ejemplo, si solo hay 3 clases en el conjunto de datos, LDA puede encontrar un máximo de 2 componentes.\n",
    "- Finalmente, **LDA es más eficaz que PCA para conjuntos de datos de clasificación porque LDA reduce la dimensionalidad de los datos maximizando la separabilidad de clases. Es más fácil trazar límites de decisión para datos con máxima separabilidad de clases.** Esto último aplica si tenemos un conjunto de datos con etiquetas, claro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f2e00",
   "metadata": {},
   "source": [
    "💻 Primer análisis 💻\n",
    "\n",
    "Vamos a realizar un resumen de las características del dataset y a visualizar las primeras filas para entender mejor su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11389e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, testeo = getWineDF()\n",
    "entrenamiento.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43da65",
   "metadata": {},
   "source": [
    "💻 Cantidades de observaciones por clases 💻\n",
    "\n",
    "Ejecuta la celda para ver la cantidad de observaciones por clases y el porcentaje de cada una respecto del total de observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************\")\n",
    "print(\"Cantidad de observaciones por clase:\")\n",
    "print(entrenamiento['target'].value_counts())\n",
    "print(\"****************************************\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"****************************************\")\n",
    "print(\"Porcentaje de observaciones por clase:\")\n",
    "print(entrenamiento['target'].value_counts(normalize=True) * 100)\n",
    "print(\"****************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb24fb",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "1. ¿Cuántas features tiene el dataset? ¿Los rangos de cada feature son similares? *(Obligatoria)*\n",
    "2. ¿Es un dataset balanceado?\n",
    "3. ¿Qué deberíamos hacer si las features tienen rangos muy diferentes? *(Obligatoria)*\n",
    "4. ¿Qué consecuencias puede tener que el dataset no esté balanceado desde el punto de vista de la clasificación? *(Obligatoria)*\n",
    "6. ¿Qué deberíamos hacer si la cantidad de observaciones por clase es muy diferente?\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db0d46",
   "metadata": {},
   "source": [
    "📝 *En esta celda podes escribir las respuestas a las preguntas obligatorias 1, 2 y 4* 📝\n",
    "\n",
    "\n",
    "1. El dataset tiene..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573b5ac",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">1.1 Eligiendo algunas características para clasificar</font>**\n",
    "\n",
    "Antes de utilizar PCA o LDA para reducir dimensiones, vamos a explorar un poco el dataset. Para esto, vamos a crear un mapa de calor de las correlaciones entre las features y un pairplot para visualizar las relaciones entre algunas features.\n",
    "\n",
    "💻 Por favor, ejecuta las siguientes celdas de código 💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79770c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlationForWine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairPlotofWine(features=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc762c62",
   "metadata": {},
   "source": [
    "📘\n",
    "\n",
    "- El gráfico anterior se ha generado con la función [*pairplot()*](https://seaborn.pydata.org/generated/seaborn.pairplot.html) de la librería [Seaborn](https://seaborn.pydata.org/) y es muy útil para visualizar las relaciones entre múltiples variables en un solo gráfico. El gráfico se divide en filas y columnas, donde cada fila y columna representa una variable diferente del conjunto de datos.\n",
    "- A su vez, la diagonal principal del gráfico muestra la distribución de cada variable individualmente.\n",
    "- Finalmente, los gráficos fuera de la diagonal muestran las relaciones entre pares de variables, en este caso, hemos graficado las relaciones entre las features y cómo se distribuyen las clases de vino en función de esas features.\n",
    "\n",
    "📘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70c854",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "6. Si tuvieras que elegir sólo 2 features para clasificar las clases de vino, ¿cuáles elegirías? ¿Por qué? *(Obligatoria)*\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613cb260",
   "metadata": {},
   "source": [
    "📝 *En esta celda podes escribir la respuesta a la pregunta obligatoria número 6* 📝\n",
    "\n",
    "\n",
    "6. Las features que elegiría serían..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309ddb3",
   "metadata": {},
   "source": [
    "💻 \n",
    "\n",
    "A partir de tu analisis, elige 2 features que usaremos para clasificar las clases de vino utilizando un SVM.\n",
    "\n",
    "Para esto, reemplaza donde dice `None` en las variables `feature1` y `feature2` por las características que hayas elegido en la celda de código de abajo y ejecutala para ver la frontera de decisión del clasificador SVM utilizando esas 2 features.\n",
    "\n",
    "<font color=\"#d6023a\">**IMPORTANTE: Debes escribir los nombres de las features exactamente como figura en el gráfico y además debe estar entre comillas dobles o simples**</font>\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "feature1 = \"malic_acid\"\n",
    "feature2 = \"magnesium\"\n",
    "```\n",
    "\n",
    "💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c036448",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = None\n",
    "feature2 = None\n",
    "feature1 = \"alcohol\"\n",
    "feature2 = \"color_intensity\"\n",
    "classifyWineFeatures(feature1, feature2, seed=42, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef8597",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "7. ¿Qué tan bien funciona el clasificador SVM con las features que elegiste? ¿Crees que podrías mejorar la performance eligiendo otras features? (Podes probar en la celda anterior cambiando las features).\n",
    "8. ¿Qué clases son las que más se confunden entre sí?\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714172b",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">1.2 Usando PCA y SVM para clasificar el set WINE</font>**\n",
    "\n",
    "Ahora vamos a usar PCA para reducir las 13 dimensiones del dataset a 2 dimensiones y luego entrenar un clasificador SVM con esas 2 dimensiones para ver si podemos mejorar la clasificación.\n",
    "\n",
    "💻 Corre la celda debajo para evaluar el rendimiento del clasificador SVM con las nuevas características a partir de PCA. 💻\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = 2\n",
    "classifyWinePCA(n_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d5ed6",
   "metadata": {},
   "source": [
    "Podemos ver que utilizando las primeras dos componentes logramos una accuracy global de alrededor del $96\\%$. Esto es bastante bueno considerando que estamos usando solo dos dimensiones en lugar de las 13 originales. Hemos visto también que la cantidad de varianza explicada usando sólo dos componentes es de casi el 60%, lo cual es significativo. **Esto indica que estas dos componentes principales capturan una gran parte de la información original del conjunto de datos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467e8ee",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "9. ¿Crees que el rendimiento del clasificador mejoraría su usaramos más componentes principales en lugar de 2? ¿Por qué?\n",
    "10. ¿Siempre mejoraría el rendimiento al aumentar la cantidad de componentes principales?\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d74c8a",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">1.3 Usando LDA y SVM para clasificar el set WINE</font>**\n",
    "\n",
    "Ahora vamos a usar LDA para reducir las 13 dimensiones del dataset a 2 dimensiones y luego entrenar un clasificador SVM con los datos proyectados en estas nuevas dimensiones para ver si mejoramos respecto a PCA y la elección de features de los apartados 1.1 y 1.2.\n",
    "\n",
    "💻 Ejecuta la celda debajo para evaluar el rendimiento del clasificador SVM con las nuevas características a partir de LDA. 💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyWineLDA(show_variance=False, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5802e56",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "10. Para el set de entrenamiento, ¿con qué método se clasificó mejor: ¿PCA, LDA o la elección de features? ¿Por qué? *(Obligatoria)*\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730535e",
   "metadata": {},
   "source": [
    "📝 *En esta celda podes escribir la respuesta a la pregunta obligatoria número 10* 📝\n",
    "\n",
    "\n",
    "10. Para el set de entrenamiento, el método que mejor separó los datos fue... Debido a..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa41fcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0e9f5",
   "metadata": {},
   "source": [
    "# 📊 **<font color=\"#d6b302\">2. Aplicando técnicas no supervisadas para generar categorías y clasificar datos nuevos</font>**\n",
    "\n",
    "Vamos a usar un dataset que tiene las siguientes features:\n",
    "- media_visitas_diarias\n",
    "- precio_unitario\n",
    "- unidades_vendidas_mensuales\n",
    "- valoracion_media\n",
    "\n",
    "<font color=\"#0059d6\">**La idea es generar categorías de productos a partir de estas features para luego entrenar un modelo de clasificación que nos permita predecir la categoría de un producto nuevo.**</font>\n",
    "\n",
    "<font color=\"#d6023a\">**NOTAS:**</font>\n",
    "\n",
    "1. Para este ejercicio se dispone de un *set de entrenamiento* y un *set de testeo*.\n",
    "2. El set de entrenamiento no tiene etiquetas, de hecho, debemos encontrarlas. Se utilizará para encontrar los segmentos utilizando técnicas de clustering.\n",
    "3. Todo el análisis para segmentar los datos se realizará en el set de entrenamiento.\n",
    "4. Una vez segmentados los datos, se asignarán las etiquetas encontradas a los datos del set de testeo.\n",
    "5. Luego, se entrenarán un par de modelos de clasificación utilizando las features y las etiquetas encontradas en el set de entrenamiento.\n",
    "6. Finalmente, evaluaremos el rendimiento del modelo en el set de testeo. **IMPORTANTE:** El set de testeo sí tiene etiquetas, por lo tanto podremos evaluar el rendimiento del modelo comparando las etiquetas reales con las predichas por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e5f0b",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">2.1 Eligiendo características para aplicar técnicas no supervisadas</font>**\n",
    "\n",
    "En primer lugar, vamos a generar un pairplot para determinar qué características parecen segmentar mejor los datos. Nos ayudaremos con estas features, gráficos de dispersión, dendograma y algunas métricas para intentar determinar la cantidad óptima de clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004ac78",
   "metadata": {},
   "source": [
    "💻 Ejecuta la celda de abajo para ver el pairplot de los datos 💻\n",
    "\n",
    "NOTA: En la función `pairPlotofIrTransformed()` podes elegir si aplicar o no el escalado estándar a las características. Para esto, simplemente tenes que pasar el parámetro `standard_scaler=True` o `standard_scaler=False`.\n",
    "\n",
    "Si aplicas standard scaler, las features se escalarán para que tengan media 0 y desviación estándar 1. Esto es útil cuando las features tienen diferentes unidades o rangos, ya que ayuda a que todas las features contribuyan de manera equitativa al análisis.\n",
    "\n",
    "La fórmula para estandarizar una característica es:\n",
    "\n",
    "$$ z = \\frac{(X - \\mu)}{\\sigma} $$\n",
    "\n",
    "Donde $z$ es el valor estandarizado, $X$ es el valor original de la característica, $\\mu$ es la media de la característica y $\\sigma$ es la desviación estándar de la característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairPlotofIrdataset(standard_scaler = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92030f",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "11. ¿Hay alguna diferencia en la distribución o rangos de valores que toman las features cuando se escala o no se escala? ¿Es correcto lo que ves en uno u otro caso?\n",
    "12. ¿Qué variables parecen segmentar mejor los datos?\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ba670",
   "metadata": {},
   "source": [
    "💻 \n",
    "\n",
    "A partir del análisis del pairplot debes elegir dos variables para analizar cuantos grupos podríamos formar. Primero vamos a analizar información usando K-means.\n",
    "\n",
    "De momento, **NO** vamos a aplicar clustering, sólo queremos analizar los datos y usar algunas métricas para intentar inferir la cantidad óptima de clusters.\n",
    "\n",
    "<font color=\"#d6023a\">**IMPORTANTE: Para que la celda de abajo se ejecute adecuadamente, debes escribir los nombres de las features exactamente como figura en el gráfico y además debe estar entre comillas dobles o simples**</font>\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```\n",
    "💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae65412",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = None# acá pone la feature 1\n",
    "feature2 = None# acá pone la feature 2\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "kmeansIrdatasetAnalysis(feature1, feature2, figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a78842",
   "metadata": {},
   "source": [
    "💻 \n",
    "\n",
    "Ahora vamos a usar un dendograma para complementar el análisis anterior. El dendograma nos ayudará a visualizar cómo se agrupan las muestras en función de las características seleccionadas y a intentar inferir la cantidad óptima de clusters.\n",
    "\n",
    "<font color=\"#d6023a\">**IMPORTANTE: Tene en cuenta que hay que escribir los nombres de las features exactamente como figura en el gráfico y además debe estar entre comillas dobles o simples**</font>\n",
    "\n",
    "💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aeb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = None# acá pone la feature 1\n",
    "feature2 = None# acá pone la feature 2\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "deondoIrdataset(feature1, feature2, used_all_features = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e4d0f",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">2.2 Generando categorías</font>**\n",
    "\n",
    "Con los gráficos y métricas anteriores, estamos en condiciones de elegir la cantidad de cluster o *categorías* a partir de los datos.\n",
    "\n",
    "Vamos a aplicar K-means y clustering jerárquico para generar las categorías y a partir de los datos segmentados vamos a analizar las métricas para decidir qué técnica usar para generar las categorías definitivas.\n",
    "\n",
    "Encima de cada gráfico vas a ver algunas métricas que te ayudarán a decidir la cantidad de clusters y la técnica a usar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb10418",
   "metadata": {},
   "source": [
    "💻 \n",
    "\n",
    "Ejecuta la celda de abajo para aplicar K-means y clustering jerárquico y ver las métricas asociadas a cada técnica. Utilizá las features que elegiste en el *apartado 2.1*. Además, en el caso de K-means, vas a tener que especificar una cantidad de cluster, para esto, reemplazá la palabra `None` en la variable `n_clusters` por la cantidad de clusters que creas conveniente.\n",
    "\n",
    "Por otro lado recorda que <font color=\"#d6023a\">**el nombre de las categorías dentro de `feature1` y `feature2` se deben escribir exactamente como figuran en el gráfico y además debe estar entre comillas dobles o simples**</font>.\n",
    "\n",
    "Ejemplo de uso:\n",
    "\n",
    "```python\n",
    "n_clusters = 3\n",
    "umbral_dendo = 7\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```\n",
    "\n",
    "💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "feature1 = None# acá pone la feature 1\n",
    "feature2 = None# acá pone la feature 2\n",
    "umbral_dendo = 7\n",
    "\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "\n",
    "kmeansIrdatasetClustering(n_clusters=n_clusters, feature1=feature1, feature2=feature2)\n",
    "jerarquicoIrdatasetClustering(feature1=feature1, feature2=feature2, umbral=umbral_dendo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dab5af",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "13. ¿Qué técnica usarías para generar las categorías? ¿Por qué? *(Obligatoria)*\n",
    "14. ¿Qué cantidad de clusters elegirías? ¿Por qué? *(Obligatoria)*\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a7cef",
   "metadata": {},
   "source": [
    "📝 *En esta celda podes escribir las respuestas a las preguntas obligatorias número 13 y 14* 📝\n",
    "\n",
    "13. La técnica que usaría para generar las categorías es...\n",
    "14. La cantidad de clusters que elegiría es..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec005320",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">2.3 Entrenando un clasificador</font>**\n",
    "\n",
    "Ahora que hemos generado las categorías, vamos a entrenar un par de clasificadores para predecir la categoría de un producto nuevo.\n",
    "\n",
    "Usaremos un Linear Discriminant Analysis (LDA) ya que es un clasificador lineal simple y efectivo para problemas de clasificación multiclase y un SVM.\n",
    "\n",
    "Usaremos los datos de entrenamiento con las categorías generadas para entrenar ambos clasificadores y luego evaluaremos su rendimiento en el set de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb25035",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">📘 Resumen de lo realizado 📘</font>\n",
    "\n",
    "Hasta ahora, hemos realizado los siguientes pasos:\n",
    "\n",
    "1. Analizamos el dataset de entrenamiento y seleccionamos dos características que parecen segmentar bien los datos.\n",
    "2. Usamos K-means y clustering jerárquico para generar categorías a partir de las características seleccionadas.\n",
    "3. Elegimos la técnica y la cantidad de clusters para generar las categorías definitivas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834a590",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">📘 Preparando los datos  de testeo 📘</font>\n",
    "\n",
    "*¿Debemos preparar los datos de testeo de alguna manera especial?*\n",
    "\n",
    "<font color=\"#3aa256\">**¡SI!**</font>, lo que debemos hacer es aplicar el mismo pre-procesamiento inicial que aplicamos a los datos de entrenamiento, en este caso, estandarizar las features. No obstante, si hubiéramos realizado más procesamientos, también deberíamos aplicarlos aquí.\n",
    "\n",
    "Luego, cada observación del set de testeo se clasificará en una de las categorías generadas a partir del set de entrenamiento. Paso siguiente, evaluaremos el rendimiento del clasificador comparando las etiquetas reales con las predichas por el modelo.\n",
    "\n",
    "Sigamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b3b56",
   "metadata": {},
   "source": [
    "#### 📊 **<font color=\"#d6b302\">💻 2.3.1. Entrenando y clasificando con LDA 💻</font>**\n",
    "\n",
    "Para esta parte del ejercicio usaremos la función `classifyClusteringLDA()` que está definida en la celda de código de abajo.\n",
    "\n",
    "<font color=\"#d6023a\">**Consideraciones:**</font>\n",
    "\n",
    "Para que la misma funcione correctamente, debemos pasarle los siguientes parámetros:\n",
    "\n",
    "- `metodo`: Técnica de clustering a usar, puede ser `\"kmeans\"` o `\"jerarquico\"`. Hay que escribirlo entre comillas dobles o simples, y exactamente como está esscrito acá.\n",
    "- Hay que elegir las features que se usaron para generar las categorías. Para esto, reemplaza donde dice `None` en las variables `feature1` y `feature2` por las características que hayas elegido en el apartado *2.1*. Recorda que deben estar entre comillas dobles o simples y deben coincidir con las que usaste para generar las categorías. Ejemplo: `feature1 = \"media_visitas_diarias\"` y `feature2 = \"unidades_vendidas_mensuales\"`.\n",
    "- `n_clusters`: Número de componentes a utilizar en LDA. Debe ser un número entero positivo.\n",
    "- `umbral`: Umbral de distancia para el clustering jerárquico. Si se hace `metodo = \"kmeans\"`, entonces umbral no se usa.\n",
    "\n",
    "Ejemplo usando K-means con 3 clusters y las features \"media_visitas_diarias\" y \"unidades_vendidas_mensuales\":\n",
    "\n",
    "```python\n",
    "metodo = \"kmeans\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```\n",
    "\n",
    "Por favor, ejecuta la celda de abajo para entrenar y evaluar el rendimiento del clasificador LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "metodo = \"kmeans\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = None\n",
    "feature2 = None\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "\n",
    "classifyClusteringLDA(method = metodo, umbral = umbral, n_clusters = n_clusters,\n",
    "                      feature1 = feature1, feature2 = feature2, cmap = \"Pastel1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77d01f",
   "metadata": {},
   "source": [
    "#### 📊 **<font color=\"#d6b302\">💻 2.3.2. Entrenando y clasificando con SVM 💻</font>**\n",
    "\n",
    "Para este ejercicio usaremos la función `classifyClusteringSVM()` que está definida en la celda de código de abajo.\n",
    "\n",
    "<font color=\"#d6023a\">**Consideraciones:**</font>\n",
    "\n",
    "Para que la misma funcione correctamente, debemos pasarle los siguientes parámetros:\n",
    "\n",
    "- `metodo`: Técnica de clustering a usar, puede ser `\"kmeans\"` o `\"jerarquico\"`. Hay que escribirlo entre comillas dobles o simples, y exactamente como está esscrito acá.\n",
    "- Hay que elegir las features que se usaron para generar las categorías. Para esto, reemplaza donde dice `None` en las variables `feature1` y `feature2` por las características que hayas elegido en el apartado 2.1. Recorda que deben estar entre comillas dobles o simples y deben coincidir con las que usaste para generar las categorías. Ejemplo: `feature1 = \"media_visitas_diarias\"` y `feature2 = \"unidades_vendidas_mensuales\"`.\n",
    "- `n_clusters`: Número de componentes a utilizar en LDA. Debe ser un número entero positivo.\n",
    "- `umbral`: Umbral de distancia para el clustering jerárquico. Si se hace `metodo = \"kmeans\"`, entonces umbral no se usa.\n",
    "\n",
    "Ejemplo usando clustering Jerárquico, un umbral de 7 y con las features \"media_visitas_diarias\" y \"unidades_vendidas_mensuales\":\n",
    "\n",
    "```python\n",
    "metodo = \"jerarquico\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364344a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metodo = \"jerarquico\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "classifyClusteringSVM(method=metodo, umbral=umbral, feature1=feature1, feature2=feature2,\n",
    "                      n_clusters=n_clusters, seed=42, cmap=\"Pastel1\", test_size=0.3, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7da40c",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "15. ¿Qué técnica de clasificación funcionó mejor: LDA o SVM? ¿Por qué? *(Obligatoria)*\n",
    "16. Cuando aplicamos LDA para clasificar a partir de dos dimensiones, ¿estas dimensiones maximizan la separabilidad de las clases a la vez que se reduce la varianza dentro de cada clase? *(Obligatoria)*\n",
    "\n",
    "---❓---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f8d67",
   "metadata": {},
   "source": [
    "📝 *En esta celda podes escribir las respuestas a las preguntas obligatorias número 15 y 16* 📝\n",
    "\n",
    "15. La técnica que usaría para generar las categorías es...\n",
    "16. Al aplicar LDA para clasificar lo que sucede es..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacaff0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc82fea",
   "metadata": {},
   "source": [
    "## 📊 **<font color=\"#d6b302\">3. Prediciendo velocidad de venta</font>**\n",
    "\n",
    "En este ejercicio vamos a usar un dataset que tiene las siguientes features:\n",
    "\n",
    "- product_length_cm\n",
    "- packaging_width_cm\n",
    "- shelf_presence_score\n",
    "- sales_velocity\n",
    "- price_usd\n",
    "- product_category\n",
    "- customer_satisfaction\n",
    "\n",
    "La idea es predecir la velocidad de venta (*sales_velocity*) a partir de analizar y procesar los datos.\n",
    "\n",
    "De manera básica, lo que haremos es:\n",
    "1. analizar y entender el dataset, \n",
    "2. luego vamos pre-procesar los datos,\n",
    "3. aplicaremos un regresor lineal para predecir la velocidad de venta,\n",
    "4. finalmente evaluaremos el rendimiento del modelo en el set de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e46abf",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">💻 3.1 Analisis previo 💻</font>**\n",
    "\n",
    "Como ya sabemos, es importante entender el dataset con el que vamos a trabajar. Para esto, vamos a realizar un análisis descriptivo básico del dataset de entrenamiento.\n",
    "\n",
    "💻 Por favor, ejecuta la celda de código de abajo para realizar un análisis descriptivo básico del dataset de entrenamiento. 💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basicAnalysisSegmentedDataset(pairplot_height=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce22643",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">📘 3.1.1. Conclusiones iniciales </font>\n",
    "\n",
    "A partir de los datos anteriores podemos inferir algunas cosas sobre el dataset.\n",
    "\n",
    "1. Los productos están muy solapados entre sí, si observamos el pairplot, podemos ver que las diferentes categorías de productos no están claramente separadas en el espacio de características.\n",
    "\n",
    "2. **Multicolinealidad**: Algunas variables están muy correlacionadas entre sí, como por ejemplo *shelf_presence_score*, *price_usd* y *customer_satisfaction* ($>0.9$) están muy correlacionadas con la variable objetivo *sales_velocity*. Esto puede indicar que estas variables miden aspectos similares del producto o que están influenciadas por factores comunes. En este contexto, podráimos decir que estas variables son redundantes y podrían ser eliminadas o combinadas para simplificar el modelo. No obstante, está claro que estas variables tienen una muy alta correlación positiva, y por lo tanto, aportan información relevante para predecir la velocidad de venta dado que cuando una crece, la velocidad de venta también tiende a crecer.\n",
    "\n",
    "3. La variable *packaging_width_cm* tiene una correlación negativa moderada con *sales_velocity* (aprox. $-0.33$), lo que sugiere que a medida que aumenta el ancho del empaque, la velocidad de ventas tiende a disminuir. Esto podría indicar que los productos con empaques más anchos son menos atractivos para los consumidores o que tienen un precio más alto. En todo caso, esta variable aporta *información distinta* y sería bueno conservarla.\n",
    "\n",
    "4. Observando los valores de Skewness* y Kurtosis**, podemos ver que en general la distribución de las variables son relativamente simétricas, aunque algunas están algo más alejadas de una distribución normal.\n",
    "\n",
    "* El Skewness mide la asimetría de la distribución de los datos respecto de la media. Un valor de skewness cercano a 0 indica una distribución simétrica, mientras que valores positivos o negativos indican asimetría hacia la derecha o hacia la izquierda, respectivamente.\n",
    "** El Kurtosis mide la \"concentración\" de los datos en torno a la media. Un valor de kurtosis cercano a cero indica una distribución normal, mientras que valores positivos o negativos indican distribuciones con colas más pesadas o más ligeras, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa1a4b",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "17. Respecto de la poca separabilidad entre las clases, ¿qué técnicas podríamos usar para mejorar la separación entre clases y por qué? *(Obligatoria)*\n",
    "18. Respecto de la alta correlación entre algunas variables, ¿cómo podríamos hacer para juntar variables y así reducir la redundancia? *(Obligatoria)*\n",
    "19. ¿Hay variables que tengan escalas muy distintas entre sí? ¿Cuáles? ¿Qué acciones podrías tomar?\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2c555",
   "metadata": {},
   "source": [
    "📝 *En esta celda podes escribir las respuestas a las preguntas obligatorias número 17 y 18|* 📝\n",
    "\n",
    "17. ...\n",
    "18. ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf31d3",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">💻 3.2 Procesando datos 💻</font>**\n",
    "\n",
    "A continuación aplicaremos un pipeline de pre-procesamiento a los datos de entrenamiento y testeo.\n",
    "\n",
    "Para esto, usaremos una función llamada `processSegmentedDataset()`.\n",
    "\n",
    "Esta función admite algunas combinaciones para procesar los datos.\n",
    "\n",
    "1. Es posible procesar los datos aplicando PCA a las columnas *'product_length_cm'*, *'shelf_presence_score'*, *'price_usd'*, *'customer_satisfaction'* para obtener nuevas componentes (por defecto 2) que reemplacen a estas variables. Esto puede ayudar a reducir la dimensionalidad y eliminar la multicolinealidad entre estas variables. Para esto, debemos pasar el parámetro `apply_pca=True` y `n_components_pca` con la cantidad de componentes que queremos obtener.  Si usamos PCA, la función aplicará escalado estándar a las columnas que no se usen en PCA y luego aplicará PCA a las columnas indicadas. La función retornará un set de datos de entrenamiento nuevo con las columnas PCA1 y PCA2 (o más si elegimos más componentes) y las demás columnas que no se usaron en PCA.\n",
    "2. El set de datos original tiene una columna llamada 'product_category' que es una variable categórica. Podemos usar las variables categóricas transformadas con OneHotEncoding haciend `use_product_category=True`, si no quieremos usar esta variable, debemos pasar `use_product_category=False`.\n",
    "3. En el caso de no usar PCA la función procesará todas las columnas numéricas (excepto las categóricas) aplicando escalado estándar. Sin embargo, es posible elegir una o más característica de interés. Se dejan algunos ejemplos abajo.\n",
    "\n",
    "Supongamos que queremos aplicar PCA con 2 componentes y usar la variable categórica 'product_category'. Entonces, debemos ejecutar la función de la siguiente manera:\n",
    "\n",
    "```python\n",
    "apply_pca = True\n",
    "use_product_category = True\n",
    "n_components_pca = 2\n",
    "features_selected = [\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\"]\n",
    "```\n",
    "\n",
    "Supongamos que sólo quisieramos usar \"customer_satisfaction\" y no usar PCA, podríamos ejecutar la función de la siguiente manera:\n",
    "\n",
    "```python\n",
    "apply_pca = False\n",
    "use_product_category = False\n",
    "n_components_pca = 2\n",
    "features_selected = [\"customer_satisfaction\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd7eb0",
   "metadata": {},
   "source": [
    "💻 Por favor, elegí lo que queres hacer y ejecuta la celda de abajo 💻\n",
    "\n",
    "Para entender qué hace la función, podes modificar cada una de las variables según se explica. Cada vez que ejecutes la celda, se procesarán los datos de entrenamiento y se mostrará un pequeño resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "##características de itneres [\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\"]\n",
    "apply_pca = True\n",
    "use_product_category = True\n",
    "n_components_pca = 2\n",
    "features_selected = [\"customer_satisfaction\"] ## posibles[\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\",\"packaging_width_cm\"]\n",
    "processSegmentedDataset(apply_pca,\n",
    "                        n_components_pca,\n",
    "                        use_product_category,\n",
    "                        features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380bdd8",
   "metadata": {},
   "source": [
    "### 📊 **<font color=\"#d6b302\">💻 3.3 Prediciendo velocidad de venta 💻</font>**\n",
    "\n",
    "Ahora vamos a usar un Regresor Lineal para predecir el precio de venta a partir de los datos procesados.\n",
    "\n",
    "Al igual que antes, vas a poder decidir si usar PCA o no y si usar la variable categórica 'product_category' o no o bien elegir una o más características de interés.\n",
    "\n",
    "LA función que usaremos para esto es `predictSalesVelocity()`. La misma nos arroja los siguientes resultados:\n",
    "\n",
    "1. Valor $R^2$ el cual indica qué tan bien se ajusta el modelo a los datos. Un valor de $R^2$ cercano a 1 indica un buen ajuste, mientras que un valor cercano a 0 indica un mal ajuste.\n",
    "2. RMSE (Root Mean Squared Error) el cual mide la diferencia promedio entre los valores predichos por el modelo y los valores reales. Un valor de RMSE más bajo indica un mejor rendimiento del modelo.\n",
    "3. MAE (Mean Absolute Error) el cual mide la diferencia promedio absoluta entre los valores predichos por el modelo y los valores reales. Al igual que RMSE, un valor de MAE más bajo indica un mejor rendimiento del modelo.\n",
    "4. Una tabla con los primeros 5 valores reales, los predichos, su diferencia absoluta y el error porcentual.\n",
    "5. Un gráfico que muestra los valores reales vs los valores predichos en un scatter plot junto a una línea roja que representa la línea ideal donde los valores predichos son iguales a los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_pca = True\n",
    "use_product_category = True\n",
    "n_components_pca = 2\n",
    "features_selected = [\"packaging_width_cm\"] ## posibles[\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\",\"packaging_width_cm\"]\n",
    "\n",
    "predictSalesVelocity(apply_pca,\n",
    "                     n_components_pca,\n",
    "                     use_product_category,\n",
    "                     features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b94854",
   "metadata": {},
   "source": [
    "---❓---\n",
    "\n",
    "20. En base a las métricas arrojadas por la función anterior ¿Qué tan bien funciona el modelo si se usa PCA y las variables categóricas?\n",
    "21. ¿Qué tan bien funciona el modelo si se usan por ejemplo las columnas \"price_usd\" y \"customer_satisfaction\"?\n",
    "22. ¿Qué tan bien funciona el modelo si sólo se usa la columna packaging_width_cm? ¿Por qué crees que arroja este desempeño? *(Obligatoria)*\n",
    "\n",
    "---❓---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e306029",
   "metadata": {},
   "source": [
    "## 📊 **<font color=\"#d6b302\">💻 4. Clasificando categorías 💻</font>**\n",
    "\n",
    "En este ejercicio vamos a usar el mismo dataset del ejercicio 3, el cual recordemos tiene las siguientes features:\n",
    "\n",
    "- product_length_cm\n",
    "- packaging_width_cm\n",
    "- shelf_presence_score\n",
    "- sales_velocity\n",
    "- price_usd\n",
    "- product_category\n",
    "- customer_satisfaction\n",
    "\n",
    "Con este ejercicio se buscan dos cosas:\n",
    "\n",
    "1. Aplicar técnicas de PCA y LDA para intentar mejorar la separabilidad de los datos y mejorar la clasificación.\n",
    "2. Demostrar, que a veces, no alcanza con técnicas sencillas como hemos visto y necesitamos técnicas más avanzadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
