{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702ad69d",
   "metadata": {},
   "source": [
    "# <font color=\"#3A40A2\">ğŸ“˜ 5. Combinando Aprendizaje No Supervisado y Aprendizaje Supervisado</font>\n",
    "\n",
    "**Materia: Ciencia de Datos aplicada a los Negocios - Universidad de San AndrÃ©s**\n",
    "\n",
    "**Autor: [Lucas BALDEZZARI](https://www.linkedin.com/in/lucasbaldezzari/)**\n",
    "\n",
    "**2025**\n",
    "\n",
    "> Este material es para fines educativos y no debe ser utilizado para fines comerciales. El contenido pertenece a la *Universidad de San AndrÃ©s* y no debe ser reproducido sin el permiso explÃ­cito de la instituciÃ³n y del autor de este repositorio quien es [LUCAS BALDEZZARI](https://www.linkedin.com/feed/).\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebbcc5",
   "metadata": {},
   "source": [
    "## <font color=\"#004eb3\">Temas de la Colab</font>\n",
    "\n",
    "- Para esta clase aplicaremos los conceptos vistos en las clases anteriores para combinar tÃ©cnicas de Aprendizaje No Supervisado y Aprendizaje Supervisado. En particular, veremos cÃ³mo utilizar tÃ©cnicas de reducciÃ³n de dimensionalidad para mejorar el rendimiento de modelos supervisados.\n",
    "\n",
    "Es importante prestar atenciÃ³n a los siguientes Ã­conos o emojis que aparezcan a lo largo de la Colab.\n",
    "\n",
    "- ğŸ“˜ **TeorÃ­a**: Conceptos teÃ³ricos.\n",
    "- ğŸ“š **Lectura**: Material adicional que puedes consultar para profundizar en el tema.\n",
    "- ğŸ“Š **Ejemplo**: Ejemplo para demostrar y/o reforzar conceptos.\n",
    "- ğŸ”— **Enlace**: Recursos externos que puedes visitar para obtener mÃ¡s informaciÃ³n.\n",
    "- â“ **Pregunta**: Preguntas disparadas a lo largo del contenido para reflexionar sobre los ejemplos y conceptos tratados.\n",
    "- ğŸ’» **CÃ³digo**: Indica que la celda de abajo es una celda con cÃ³digo y debe ser ejecutada para ver su contenido.\n",
    "- ğŸ“ **Respuestas**: Respuestas a las preguntas planteadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e253dc4",
   "metadata": {},
   "source": [
    "### **<font color=\"#0205d6\">Integrantes del grupo</font>**\n",
    "\n",
    "Por favor, colocar los nombres de los/as integrantes del grupo que trabajÃ³ en esta Colab.\n",
    "- Integrante 1\n",
    "- Integrante 2\n",
    "- Integrante 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14fa59",
   "metadata": {},
   "source": [
    "ğŸ’» Por favor, ejecuta la celda de abajo para clonar el repositorio y poder trabajar ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394192d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## **** CÃ“DIGO PYTHON ****\n",
    "\n",
    "##Clonamos el repositorio para poder usar las funciones\n",
    "## Esperar unos segundos hasta ver un 100% de descarga\n",
    "# !git clone https://github.com/lucasbaldezzari/cdan.git\n",
    "\n",
    "##importamos las funciones a usar\n",
    "from funciones.combinations import *\n",
    "# from funciones.utils import * ##importo funciones a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d39d1",
   "metadata": {},
   "source": [
    "# ğŸ“Š **<font color=\"#d6b302\">1. LDA vs PCA para reducciÃ³n de dimensionalidad y clasificaciÃ³n</font>**\n",
    "\n",
    "En este primer ejercicio vamos a usar LDA y PCA para reducir dimensiones y comparar la performance de un SVM en ambos casos.\n",
    "\n",
    "Usaremos el set de datos llamado *Wine*, donde puede obtenerse informaciÃ³n del mismo en [Wine](https://archive.ics.uci.edu/dataset/109/wine) y [Wine recognition dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset) que contiene 13 features y 3 clases. El objetivo es predecir la clase a la que pertenece cada muestra.\n",
    "\n",
    "Este set de datos posee 178 muestras. Las caracterÃ­sticas son resultados de anÃ¡lisis quÃ­micos de diferentes vinos. La variable objetivo es la clase del vino, que puede ser 1, 2 o 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e53dd4",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">ğŸ“˜ Repaso teÃ³rico ğŸ“˜</font>\n",
    "\n",
    "- PCA realiza la reducciÃ³n de dimensionalidad maximizando la varianza de los datos. En la mayorÃ­a de los casos, la **estandarizaciÃ³n** de las caracterÃ­sticas es necesaria antes de aplicar PCA.\n",
    "- LDA realiza la reducciÃ³n de dimensionalidad maximizando la separabilidad de clases de los conjuntos de datos de clasificaciÃ³n.\n",
    "- PCA no requiere etiquetas de clase. Por esta razÃ³n, podemos usarlo con clasificaciÃ³n, regresiÃ³n e incluso con datos no etiquetados.\n",
    "- LDA requiere etiquetas de clase. Por lo tanto, se utiliza con conjuntos de datos de clasificaciÃ³n.\n",
    "- PCA encuentra un conjunto de caracterÃ­sticas no correlacionadas en un espacio de menor dimensiÃ³n. Esto significa que las nuevas caracterÃ­sticas (componentes principales) son combinaciones lineales de las caracterÃ­sticas originales.\n",
    "- Como hemos visto, LDA se puede utilizar tanto para tareas supervisadas como no supervisadas. PCA solo se puede utilizar para la reducciÃ³n de dimensionalidad no supervisada.\n",
    "- El nÃºmero mÃ¡ximo de componentes que PCA puede encontrar es igual al nÃºmero de caracterÃ­sticas de entrada (dimensionalidad original) del conjunto de datos. Sin embargo, en general queremos encontrar un nÃºmero mÃ¡s bajo de componentes que capture la mayor cantidad posible de la varianza en los datos originales.\n",
    "- El nÃºmero mÃ¡ximo de componentes que LDA puede encontrar es igual al nÃºmero de clases menos uno en el conjunto de datos de clasificaciÃ³n. Por ejemplo, si solo hay 3 clases en el conjunto de datos, LDA puede encontrar un mÃ¡ximo de 2 componentes.\n",
    "- Finalmente, **LDA es mÃ¡s eficaz que PCA para conjuntos de datos de clasificaciÃ³n porque LDA reduce la dimensionalidad de los datos maximizando la separabilidad de clases. Es mÃ¡s fÃ¡cil trazar lÃ­mites de decisiÃ³n para datos con mÃ¡xima separabilidad de clases.** Esto Ãºltimo aplica si tenemos un conjunto de datos con etiquetas, claro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f2e00",
   "metadata": {},
   "source": [
    "ğŸ’» Primer anÃ¡lisis ğŸ’»\n",
    "\n",
    "Vamos a realizar un resumen de las caracterÃ­sticas del dataset y a visualizar las primeras filas para entender mejor su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11389e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento, testeo = getWineDF()\n",
    "entrenamiento.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43da65",
   "metadata": {},
   "source": [
    "ğŸ’» Cantidades de observaciones por clases ğŸ’»\n",
    "\n",
    "Ejecuta la celda para ver la cantidad de observaciones por clases y el porcentaje de cada una respecto del total de observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************\")\n",
    "print(\"Cantidad de observaciones por clase:\")\n",
    "print(entrenamiento['target'].value_counts())\n",
    "print(\"****************************************\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"****************************************\")\n",
    "print(\"Porcentaje de observaciones por clase:\")\n",
    "print(entrenamiento['target'].value_counts(normalize=True) * 100)\n",
    "print(\"****************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb24fb",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "1. Â¿CuÃ¡ntas features tiene el dataset? Â¿Los rangos de cada feature son similares? *(Obligatoria)*\n",
    "2. Â¿Es un dataset balanceado?\n",
    "3. Â¿QuÃ© deberÃ­amos hacer si las features tienen rangos muy diferentes? *(Obligatoria)*\n",
    "4. Â¿QuÃ© consecuencias puede tener que el dataset no estÃ© balanceado desde el punto de vista de la clasificaciÃ³n? *(Obligatoria)*\n",
    "6. Â¿QuÃ© deberÃ­amos hacer si la cantidad de observaciones por clase es muy diferente?\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db0d46",
   "metadata": {},
   "source": [
    "ğŸ“ *En esta celda podes escribir las respuestas a las preguntas obligatorias 1, 2 y 4* ğŸ“\n",
    "\n",
    "\n",
    "1. El dataset tiene..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573b5ac",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">1.1 Eligiendo algunas caracterÃ­sticas para clasificar</font>**\n",
    "\n",
    "Antes de utilizar PCA o LDA para reducir dimensiones, vamos a explorar un poco el dataset. Para esto, vamos a crear un mapa de calor de las correlaciones entre las features y un pairplot para visualizar las relaciones entre algunas features.\n",
    "\n",
    "ğŸ’» Por favor, ejecuta las siguientes celdas de cÃ³digo ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79770c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlationForWine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairPlotofWine(features=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc762c62",
   "metadata": {},
   "source": [
    "ğŸ“˜\n",
    "\n",
    "- El grÃ¡fico anterior se ha generado con la funciÃ³n [*pairplot()*](https://seaborn.pydata.org/generated/seaborn.pairplot.html) de la librerÃ­a [Seaborn](https://seaborn.pydata.org/) y es muy Ãºtil para visualizar las relaciones entre mÃºltiples variables en un solo grÃ¡fico. El grÃ¡fico se divide en filas y columnas, donde cada fila y columna representa una variable diferente del conjunto de datos.\n",
    "- A su vez, la diagonal principal del grÃ¡fico muestra la distribuciÃ³n de cada variable individualmente.\n",
    "- Finalmente, los grÃ¡ficos fuera de la diagonal muestran las relaciones entre pares de variables, en este caso, hemos graficado las relaciones entre las features y cÃ³mo se distribuyen las clases de vino en funciÃ³n de esas features.\n",
    "\n",
    "ğŸ“˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70c854",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "6. Si tuvieras que elegir sÃ³lo 2 features para clasificar las clases de vino, Â¿cuÃ¡les elegirÃ­as? Â¿Por quÃ©? *(Obligatoria)*\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613cb260",
   "metadata": {},
   "source": [
    "ğŸ“ *En esta celda podes escribir la respuesta a la pregunta obligatoria nÃºmero 6* ğŸ“\n",
    "\n",
    "\n",
    "6. Las features que elegirÃ­a serÃ­an..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309ddb3",
   "metadata": {},
   "source": [
    "ğŸ’» \n",
    "\n",
    "A partir de tu analisis, elige 2 features que usaremos para clasificar las clases de vino utilizando un SVM.\n",
    "\n",
    "Para esto, reemplaza donde dice `None` en las variables `feature1` y `feature2` por las caracterÃ­sticas que hayas elegido en la celda de cÃ³digo de abajo y ejecutala para ver la frontera de decisiÃ³n del clasificador SVM utilizando esas 2 features.\n",
    "\n",
    "<font color=\"#d6023a\">**IMPORTANTE: Debes escribir los nombres de las features exactamente como figura en el grÃ¡fico y ademÃ¡s debe estar entre comillas dobles o simples**</font>\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "feature1 = \"malic_acid\"\n",
    "feature2 = \"magnesium\"\n",
    "```\n",
    "\n",
    "ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c036448",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = None\n",
    "feature2 = None\n",
    "feature1 = \"alcohol\"\n",
    "feature2 = \"color_intensity\"\n",
    "classifyWineFeatures(feature1, feature2, seed=42, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef8597",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "7. Â¿QuÃ© tan bien funciona el clasificador SVM con las features que elegiste? Â¿Crees que podrÃ­as mejorar la performance eligiendo otras features? (Podes probar en la celda anterior cambiando las features).\n",
    "8. Â¿QuÃ© clases son las que mÃ¡s se confunden entre sÃ­?\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714172b",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">1.2 Usando PCA y SVM para clasificar el set WINE</font>**\n",
    "\n",
    "Ahora vamos a usar PCA para reducir las 13 dimensiones del dataset a 2 dimensiones y luego entrenar un clasificador SVM con esas 2 dimensiones para ver si podemos mejorar la clasificaciÃ³n.\n",
    "\n",
    "ğŸ’» Corre la celda debajo para evaluar el rendimiento del clasificador SVM con las nuevas caracterÃ­sticas a partir de PCA. ğŸ’»\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = 2\n",
    "classifyWinePCA(n_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d5ed6",
   "metadata": {},
   "source": [
    "Podemos ver que utilizando las primeras dos componentes logramos una accuracy global de alrededor del $96\\%$. Esto es bastante bueno considerando que estamos usando solo dos dimensiones en lugar de las 13 originales. Hemos visto tambiÃ©n que la cantidad de varianza explicada usando sÃ³lo dos componentes es de casi el 60%, lo cual es significativo. **Esto indica que estas dos componentes principales capturan una gran parte de la informaciÃ³n original del conjunto de datos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467e8ee",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "9. Â¿Crees que el rendimiento del clasificador mejorarÃ­a su usaramos mÃ¡s componentes principales en lugar de 2? Â¿Por quÃ©?\n",
    "10. Â¿Siempre mejorarÃ­a el rendimiento al aumentar la cantidad de componentes principales?\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d74c8a",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">1.3 Usando LDA y SVM para clasificar el set WINE</font>**\n",
    "\n",
    "Ahora vamos a usar LDA para reducir las 13 dimensiones del dataset a 2 dimensiones y luego entrenar un clasificador SVM con los datos proyectados en estas nuevas dimensiones para ver si mejoramos respecto a PCA y la elecciÃ³n de features de los apartados 1.1 y 1.2.\n",
    "\n",
    "ğŸ’» Ejecuta la celda debajo para evaluar el rendimiento del clasificador SVM con las nuevas caracterÃ­sticas a partir de LDA. ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyWineLDA(show_variance=False, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5802e56",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "10. Para el set de entrenamiento, Â¿con quÃ© mÃ©todo se clasificÃ³ mejor: Â¿PCA, LDA o la elecciÃ³n de features? Â¿Por quÃ©? *(Obligatoria)*\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730535e",
   "metadata": {},
   "source": [
    "ğŸ“ *En esta celda podes escribir la respuesta a la pregunta obligatoria nÃºmero 10* ğŸ“\n",
    "\n",
    "\n",
    "10. Para el set de entrenamiento, el mÃ©todo que mejor separÃ³ los datos fue... Debido a..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa41fcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0e9f5",
   "metadata": {},
   "source": [
    "# ğŸ“Š **<font color=\"#d6b302\">2. Aplicando tÃ©cnicas no supervisadas para generar categorÃ­as y clasificar datos nuevos</font>**\n",
    "\n",
    "Vamos a usar un dataset que tiene las siguientes features:\n",
    "- media_visitas_diarias\n",
    "- precio_unitario\n",
    "- unidades_vendidas_mensuales\n",
    "- valoracion_media\n",
    "\n",
    "<font color=\"#0059d6\">**La idea es generar categorÃ­as de productos a partir de estas features para luego entrenar un modelo de clasificaciÃ³n que nos permita predecir la categorÃ­a de un producto nuevo.**</font>\n",
    "\n",
    "<font color=\"#d6023a\">**NOTAS:**</font>\n",
    "\n",
    "1. Para este ejercicio se dispone de un *set de entrenamiento* y un *set de testeo*.\n",
    "2. El set de entrenamiento no tiene etiquetas, de hecho, debemos encontrarlas. Se utilizarÃ¡ para encontrar los segmentos utilizando tÃ©cnicas de clustering.\n",
    "3. Todo el anÃ¡lisis para segmentar los datos se realizarÃ¡ en el set de entrenamiento.\n",
    "4. Una vez segmentados los datos, se asignarÃ¡n las etiquetas encontradas a los datos del set de testeo.\n",
    "5. Luego, se entrenarÃ¡n un par de modelos de clasificaciÃ³n utilizando las features y las etiquetas encontradas en el set de entrenamiento.\n",
    "6. Finalmente, evaluaremos el rendimiento del modelo en el set de testeo. **IMPORTANTE:** El set de testeo sÃ­ tiene etiquetas, por lo tanto podremos evaluar el rendimiento del modelo comparando las etiquetas reales con las predichas por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e5f0b",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">2.1 Eligiendo caracterÃ­sticas para aplicar tÃ©cnicas no supervisadas</font>**\n",
    "\n",
    "En primer lugar, vamos a generar un pairplot para determinar quÃ© caracterÃ­sticas parecen segmentar mejor los datos. Nos ayudaremos con estas features, grÃ¡ficos de dispersiÃ³n, dendograma y algunas mÃ©tricas para intentar determinar la cantidad Ã³ptima de clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004ac78",
   "metadata": {},
   "source": [
    "ğŸ’» Ejecuta la celda de abajo para ver el pairplot de los datos ğŸ’»\n",
    "\n",
    "NOTA: En la funciÃ³n `pairPlotofIrTransformed()` podes elegir si aplicar o no el escalado estÃ¡ndar a las caracterÃ­sticas. Para esto, simplemente tenes que pasar el parÃ¡metro `standard_scaler=True` o `standard_scaler=False`.\n",
    "\n",
    "Si aplicas standard scaler, las features se escalarÃ¡n para que tengan media 0 y desviaciÃ³n estÃ¡ndar 1. Esto es Ãºtil cuando las features tienen diferentes unidades o rangos, ya que ayuda a que todas las features contribuyan de manera equitativa al anÃ¡lisis.\n",
    "\n",
    "La fÃ³rmula para estandarizar una caracterÃ­stica es:\n",
    "\n",
    "$$ z = \\frac{(X - \\mu)}{\\sigma} $$\n",
    "\n",
    "Donde $z$ es el valor estandarizado, $X$ es el valor original de la caracterÃ­stica, $\\mu$ es la media de la caracterÃ­stica y $\\sigma$ es la desviaciÃ³n estÃ¡ndar de la caracterÃ­stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairPlotofIrdataset(standard_scaler = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92030f",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "11. Â¿Hay alguna diferencia en la distribuciÃ³n o rangos de valores que toman las features cuando se escala o no se escala? Â¿Es correcto lo que ves en uno u otro caso?\n",
    "12. Â¿QuÃ© variables parecen segmentar mejor los datos?\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ba670",
   "metadata": {},
   "source": [
    "ğŸ’» \n",
    "\n",
    "A partir del anÃ¡lisis del pairplot debes elegir dos variables para analizar cuantos grupos podrÃ­amos formar. Primero vamos a analizar informaciÃ³n usando K-means.\n",
    "\n",
    "De momento, **NO** vamos a aplicar clustering, sÃ³lo queremos analizar los datos y usar algunas mÃ©tricas para intentar inferir la cantidad Ã³ptima de clusters.\n",
    "\n",
    "<font color=\"#d6023a\">**IMPORTANTE: Para que la celda de abajo se ejecute adecuadamente, debes escribir los nombres de las features exactamente como figura en el grÃ¡fico y ademÃ¡s debe estar entre comillas dobles o simples**</font>\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```\n",
    "ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae65412",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = None# acÃ¡ pone la feature 1\n",
    "feature2 = None# acÃ¡ pone la feature 2\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "kmeansIrdatasetAnalysis(feature1, feature2, figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a78842",
   "metadata": {},
   "source": [
    "ğŸ’» \n",
    "\n",
    "Ahora vamos a usar un dendograma para complementar el anÃ¡lisis anterior. El dendograma nos ayudarÃ¡ a visualizar cÃ³mo se agrupan las muestras en funciÃ³n de las caracterÃ­sticas seleccionadas y a intentar inferir la cantidad Ã³ptima de clusters.\n",
    "\n",
    "<font color=\"#d6023a\">**IMPORTANTE: Tene en cuenta que hay que escribir los nombres de las features exactamente como figura en el grÃ¡fico y ademÃ¡s debe estar entre comillas dobles o simples**</font>\n",
    "\n",
    "ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aeb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = None# acÃ¡ pone la feature 1\n",
    "feature2 = None# acÃ¡ pone la feature 2\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "deondoIrdataset(feature1, feature2, used_all_features = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e4d0f",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">2.2 Generando categorÃ­as</font>**\n",
    "\n",
    "Con los grÃ¡ficos y mÃ©tricas anteriores, estamos en condiciones de elegir la cantidad de cluster o *categorÃ­as* a partir de los datos.\n",
    "\n",
    "Vamos a aplicar K-means y clustering jerÃ¡rquico para generar las categorÃ­as y a partir de los datos segmentados vamos a analizar las mÃ©tricas para decidir quÃ© tÃ©cnica usar para generar las categorÃ­as definitivas.\n",
    "\n",
    "Encima de cada grÃ¡fico vas a ver algunas mÃ©tricas que te ayudarÃ¡n a decidir la cantidad de clusters y la tÃ©cnica a usar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb10418",
   "metadata": {},
   "source": [
    "ğŸ’» \n",
    "\n",
    "Ejecuta la celda de abajo para aplicar K-means y clustering jerÃ¡rquico y ver las mÃ©tricas asociadas a cada tÃ©cnica. UtilizÃ¡ las features que elegiste en el *apartado 2.1*. AdemÃ¡s, en el caso de K-means, vas a tener que especificar una cantidad de cluster, para esto, reemplazÃ¡ la palabra `None` en la variable `n_clusters` por la cantidad de clusters que creas conveniente.\n",
    "\n",
    "Por otro lado recorda que <font color=\"#d6023a\">**el nombre de las categorÃ­as dentro de `feature1` y `feature2` se deben escribir exactamente como figuran en el grÃ¡fico y ademÃ¡s debe estar entre comillas dobles o simples**</font>.\n",
    "\n",
    "Ejemplo de uso:\n",
    "\n",
    "```python\n",
    "n_clusters = 3\n",
    "umbral_dendo = 7\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```\n",
    "\n",
    "ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "feature1 = None# acÃ¡ pone la feature 1\n",
    "feature2 = None# acÃ¡ pone la feature 2\n",
    "umbral_dendo = 7\n",
    "\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "\n",
    "kmeansIrdatasetClustering(n_clusters=n_clusters, feature1=feature1, feature2=feature2)\n",
    "jerarquicoIrdatasetClustering(feature1=feature1, feature2=feature2, umbral=umbral_dendo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dab5af",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "13. Â¿QuÃ© tÃ©cnica usarÃ­as para generar las categorÃ­as? Â¿Por quÃ©? *(Obligatoria)*\n",
    "14. Â¿QuÃ© cantidad de clusters elegirÃ­as? Â¿Por quÃ©? *(Obligatoria)*\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a7cef",
   "metadata": {},
   "source": [
    "ğŸ“ *En esta celda podes escribir las respuestas a las preguntas obligatorias nÃºmero 13 y 14* ğŸ“\n",
    "\n",
    "13. La tÃ©cnica que usarÃ­a para generar las categorÃ­as es...\n",
    "14. La cantidad de clusters que elegirÃ­a es..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec005320",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">2.3 Entrenando un clasificador</font>**\n",
    "\n",
    "Ahora que hemos generado las categorÃ­as, vamos a entrenar un par de clasificadores para predecir la categorÃ­a de un producto nuevo.\n",
    "\n",
    "Usaremos un Linear Discriminant Analysis (LDA) ya que es un clasificador lineal simple y efectivo para problemas de clasificaciÃ³n multiclase y un SVM.\n",
    "\n",
    "Usaremos los datos de entrenamiento con las categorÃ­as generadas para entrenar ambos clasificadores y luego evaluaremos su rendimiento en el set de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb25035",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">ğŸ“˜ Resumen de lo realizado ğŸ“˜</font>\n",
    "\n",
    "Hasta ahora, hemos realizado los siguientes pasos:\n",
    "\n",
    "1. Analizamos el dataset de entrenamiento y seleccionamos dos caracterÃ­sticas que parecen segmentar bien los datos.\n",
    "2. Usamos K-means y clustering jerÃ¡rquico para generar categorÃ­as a partir de las caracterÃ­sticas seleccionadas.\n",
    "3. Elegimos la tÃ©cnica y la cantidad de clusters para generar las categorÃ­as definitivas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834a590",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">ğŸ“˜ Preparando los datos  de testeo ğŸ“˜</font>\n",
    "\n",
    "*Â¿Debemos preparar los datos de testeo de alguna manera especial?*\n",
    "\n",
    "<font color=\"#3aa256\">**Â¡SI!**</font>, lo que debemos hacer es aplicar el mismo pre-procesamiento inicial que aplicamos a los datos de entrenamiento, en este caso, estandarizar las features. No obstante, si hubiÃ©ramos realizado mÃ¡s procesamientos, tambiÃ©n deberÃ­amos aplicarlos aquÃ­.\n",
    "\n",
    "Luego, cada observaciÃ³n del set de testeo se clasificarÃ¡ en una de las categorÃ­as generadas a partir del set de entrenamiento. Paso siguiente, evaluaremos el rendimiento del clasificador comparando las etiquetas reales con las predichas por el modelo.\n",
    "\n",
    "Sigamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b3b56",
   "metadata": {},
   "source": [
    "#### ğŸ“Š **<font color=\"#d6b302\">ğŸ’» 2.3.1. Entrenando y clasificando con LDA ğŸ’»</font>**\n",
    "\n",
    "Para esta parte del ejercicio usaremos la funciÃ³n `classifyClusteringLDA()` que estÃ¡ definida en la celda de cÃ³digo de abajo.\n",
    "\n",
    "<font color=\"#d6023a\">**Consideraciones:**</font>\n",
    "\n",
    "Para que la misma funcione correctamente, debemos pasarle los siguientes parÃ¡metros:\n",
    "\n",
    "- `metodo`: TÃ©cnica de clustering a usar, puede ser `\"kmeans\"` o `\"jerarquico\"`. Hay que escribirlo entre comillas dobles o simples, y exactamente como estÃ¡ esscrito acÃ¡.\n",
    "- Hay que elegir las features que se usaron para generar las categorÃ­as. Para esto, reemplaza donde dice `None` en las variables `feature1` y `feature2` por las caracterÃ­sticas que hayas elegido en el apartado *2.1*. Recorda que deben estar entre comillas dobles o simples y deben coincidir con las que usaste para generar las categorÃ­as. Ejemplo: `feature1 = \"media_visitas_diarias\"` y `feature2 = \"unidades_vendidas_mensuales\"`.\n",
    "- `n_clusters`: NÃºmero de componentes a utilizar en LDA. Debe ser un nÃºmero entero positivo.\n",
    "- `umbral`: Umbral de distancia para el clustering jerÃ¡rquico. Si se hace `metodo = \"kmeans\"`, entonces umbral no se usa.\n",
    "\n",
    "Ejemplo usando K-means con 3 clusters y las features \"media_visitas_diarias\" y \"unidades_vendidas_mensuales\":\n",
    "\n",
    "```python\n",
    "metodo = \"kmeans\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```\n",
    "\n",
    "Por favor, ejecuta la celda de abajo para entrenar y evaluar el rendimiento del clasificador LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "metodo = \"kmeans\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = None\n",
    "feature2 = None\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "\n",
    "classifyClusteringLDA(method = metodo, umbral = umbral, n_clusters = n_clusters,\n",
    "                      feature1 = feature1, feature2 = feature2, cmap = \"Pastel1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77d01f",
   "metadata": {},
   "source": [
    "#### ğŸ“Š **<font color=\"#d6b302\">ğŸ’» 2.3.2. Entrenando y clasificando con SVM ğŸ’»</font>**\n",
    "\n",
    "Para este ejercicio usaremos la funciÃ³n `classifyClusteringSVM()` que estÃ¡ definida en la celda de cÃ³digo de abajo.\n",
    "\n",
    "<font color=\"#d6023a\">**Consideraciones:**</font>\n",
    "\n",
    "Para que la misma funcione correctamente, debemos pasarle los siguientes parÃ¡metros:\n",
    "\n",
    "- `metodo`: TÃ©cnica de clustering a usar, puede ser `\"kmeans\"` o `\"jerarquico\"`. Hay que escribirlo entre comillas dobles o simples, y exactamente como estÃ¡ esscrito acÃ¡.\n",
    "- Hay que elegir las features que se usaron para generar las categorÃ­as. Para esto, reemplaza donde dice `None` en las variables `feature1` y `feature2` por las caracterÃ­sticas que hayas elegido en el apartado 2.1. Recorda que deben estar entre comillas dobles o simples y deben coincidir con las que usaste para generar las categorÃ­as. Ejemplo: `feature1 = \"media_visitas_diarias\"` y `feature2 = \"unidades_vendidas_mensuales\"`.\n",
    "- `n_clusters`: NÃºmero de componentes a utilizar en LDA. Debe ser un nÃºmero entero positivo.\n",
    "- `umbral`: Umbral de distancia para el clustering jerÃ¡rquico. Si se hace `metodo = \"kmeans\"`, entonces umbral no se usa.\n",
    "\n",
    "Ejemplo usando clustering JerÃ¡rquico, un umbral de 7 y con las features \"media_visitas_diarias\" y \"unidades_vendidas_mensuales\":\n",
    "\n",
    "```python\n",
    "metodo = \"jerarquico\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364344a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metodo = \"jerarquico\" # \"kmeans\" o \"jerarquico\"\n",
    "umbral =  7\n",
    "n_clusters = 3\n",
    "feature1 = \"media_visitas_diarias\"\n",
    "feature2 = \"unidades_vendidas_mensuales\"\n",
    "classifyClusteringSVM(method=metodo, umbral=umbral, feature1=feature1, feature2=feature2,\n",
    "                      n_clusters=n_clusters, seed=42, cmap=\"Pastel1\", test_size=0.3, figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7da40c",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "15. Â¿QuÃ© tÃ©cnica de clasificaciÃ³n funcionÃ³ mejor: LDA o SVM? Â¿Por quÃ©? *(Obligatoria)*\n",
    "16. Cuando aplicamos LDA para clasificar a partir de dos dimensiones, Â¿estas dimensiones maximizan la separabilidad de las clases a la vez que se reduce la varianza dentro de cada clase? *(Obligatoria)*\n",
    "\n",
    "---â“---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f8d67",
   "metadata": {},
   "source": [
    "ğŸ“ *En esta celda podes escribir las respuestas a las preguntas obligatorias nÃºmero 15 y 16* ğŸ“\n",
    "\n",
    "15. La tÃ©cnica que usarÃ­a para generar las categorÃ­as es...\n",
    "16. Al aplicar LDA para clasificar lo que sucede es..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacaff0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc82fea",
   "metadata": {},
   "source": [
    "## ğŸ“Š **<font color=\"#d6b302\">3. Prediciendo velocidad de venta</font>**\n",
    "\n",
    "En este ejercicio vamos a usar un dataset que tiene las siguientes features:\n",
    "\n",
    "- product_length_cm\n",
    "- packaging_width_cm\n",
    "- shelf_presence_score\n",
    "- sales_velocity\n",
    "- price_usd\n",
    "- product_category\n",
    "- customer_satisfaction\n",
    "\n",
    "La idea es predecir la velocidad de venta (*sales_velocity*) a partir de analizar y procesar los datos.\n",
    "\n",
    "De manera bÃ¡sica, lo que haremos es:\n",
    "1. analizar y entender el dataset, \n",
    "2. luego vamos pre-procesar los datos,\n",
    "3. aplicaremos un regresor lineal para predecir la velocidad de venta,\n",
    "4. finalmente evaluaremos el rendimiento del modelo en el set de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e46abf",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">ğŸ’» 3.1 Analisis previo ğŸ’»</font>**\n",
    "\n",
    "Como ya sabemos, es importante entender el dataset con el que vamos a trabajar. Para esto, vamos a realizar un anÃ¡lisis descriptivo bÃ¡sico del dataset de entrenamiento.\n",
    "\n",
    "ğŸ’» Por favor, ejecuta la celda de cÃ³digo de abajo para realizar un anÃ¡lisis descriptivo bÃ¡sico del dataset de entrenamiento. ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basicAnalysisSegmentedDataset(pairplot_height=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce22643",
   "metadata": {},
   "source": [
    "#### <font color=\"#3A40A2\">ğŸ“˜ 3.1.1. Conclusiones iniciales </font>\n",
    "\n",
    "A partir de los datos anteriores podemos inferir algunas cosas sobre el dataset.\n",
    "\n",
    "1. Los productos estÃ¡n muy solapados entre sÃ­, si observamos el pairplot, podemos ver que las diferentes categorÃ­as de productos no estÃ¡n claramente separadas en el espacio de caracterÃ­sticas.\n",
    "\n",
    "2. **Multicolinealidad**: Algunas variables estÃ¡n muy correlacionadas entre sÃ­, como por ejemplo *shelf_presence_score*, *price_usd* y *customer_satisfaction* ($>0.9$) estÃ¡n muy correlacionadas con la variable objetivo *sales_velocity*. Esto puede indicar que estas variables miden aspectos similares del producto o que estÃ¡n influenciadas por factores comunes. En este contexto, podrÃ¡imos decir que estas variables son redundantes y podrÃ­an ser eliminadas o combinadas para simplificar el modelo. No obstante, estÃ¡ claro que estas variables tienen una muy alta correlaciÃ³n positiva, y por lo tanto, aportan informaciÃ³n relevante para predecir la velocidad de venta dado que cuando una crece, la velocidad de venta tambiÃ©n tiende a crecer.\n",
    "\n",
    "3. La variable *packaging_width_cm* tiene una correlaciÃ³n negativa moderada con *sales_velocity* (aprox. $-0.33$), lo que sugiere que a medida que aumenta el ancho del empaque, la velocidad de ventas tiende a disminuir. Esto podrÃ­a indicar que los productos con empaques mÃ¡s anchos son menos atractivos para los consumidores o que tienen un precio mÃ¡s alto. En todo caso, esta variable aporta *informaciÃ³n distinta* y serÃ­a bueno conservarla.\n",
    "\n",
    "4. Observando los valores de Skewness* y Kurtosis**, podemos ver que en general la distribuciÃ³n de las variables son relativamente simÃ©tricas, aunque algunas estÃ¡n algo mÃ¡s alejadas de una distribuciÃ³n normal.\n",
    "\n",
    "* El Skewness mide la asimetrÃ­a de la distribuciÃ³n de los datos respecto de la media. Un valor de skewness cercano a 0 indica una distribuciÃ³n simÃ©trica, mientras que valores positivos o negativos indican asimetrÃ­a hacia la derecha o hacia la izquierda, respectivamente.\n",
    "** El Kurtosis mide la \"concentraciÃ³n\" de los datos en torno a la media. Un valor de kurtosis cercano a cero indica una distribuciÃ³n normal, mientras que valores positivos o negativos indican distribuciones con colas mÃ¡s pesadas o mÃ¡s ligeras, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa1a4b",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "17. Respecto de la poca separabilidad entre las clases, Â¿quÃ© tÃ©cnicas podrÃ­amos usar para mejorar la separaciÃ³n entre clases y por quÃ©? *(Obligatoria)*\n",
    "18. Respecto de la alta correlaciÃ³n entre algunas variables, Â¿cÃ³mo podrÃ­amos hacer para juntar variables y asÃ­ reducir la redundancia? *(Obligatoria)*\n",
    "19. Â¿Hay variables que tengan escalas muy distintas entre sÃ­? Â¿CuÃ¡les? Â¿QuÃ© acciones podrÃ­as tomar?\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2c555",
   "metadata": {},
   "source": [
    "ğŸ“ *En esta celda podes escribir las respuestas a las preguntas obligatorias nÃºmero 17 y 18|* ğŸ“\n",
    "\n",
    "17. ...\n",
    "18. ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf31d3",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">ğŸ’» 3.2 Procesando datos ğŸ’»</font>**\n",
    "\n",
    "A continuaciÃ³n aplicaremos un pipeline de pre-procesamiento a los datos de entrenamiento y testeo.\n",
    "\n",
    "Para esto, usaremos una funciÃ³n llamada `processSegmentedDataset()`.\n",
    "\n",
    "Esta funciÃ³n admite algunas combinaciones para procesar los datos.\n",
    "\n",
    "1. Es posible procesar los datos aplicando PCA a las columnas *'product_length_cm'*, *'shelf_presence_score'*, *'price_usd'*, *'customer_satisfaction'* para obtener nuevas componentes (por defecto 2) que reemplacen a estas variables. Esto puede ayudar a reducir la dimensionalidad y eliminar la multicolinealidad entre estas variables. Para esto, debemos pasar el parÃ¡metro `apply_pca=True` y `n_components_pca` con la cantidad de componentes que queremos obtener.  Si usamos PCA, la funciÃ³n aplicarÃ¡ escalado estÃ¡ndar a las columnas que no se usen en PCA y luego aplicarÃ¡ PCA a las columnas indicadas. La funciÃ³n retornarÃ¡ un set de datos de entrenamiento nuevo con las columnas PCA1 y PCA2 (o mÃ¡s si elegimos mÃ¡s componentes) y las demÃ¡s columnas que no se usaron en PCA.\n",
    "2. El set de datos original tiene una columna llamada 'product_category' que es una variable categÃ³rica. Podemos usar las variables categÃ³ricas transformadas con OneHotEncoding haciend `use_product_category=True`, si no quieremos usar esta variable, debemos pasar `use_product_category=False`.\n",
    "3. En el caso de no usar PCA la funciÃ³n procesarÃ¡ todas las columnas numÃ©ricas (excepto las categÃ³ricas) aplicando escalado estÃ¡ndar. Sin embargo, es posible elegir una o mÃ¡s caracterÃ­stica de interÃ©s. Se dejan algunos ejemplos abajo.\n",
    "\n",
    "Supongamos que queremos aplicar PCA con 2 componentes y usar la variable categÃ³rica 'product_category'. Entonces, debemos ejecutar la funciÃ³n de la siguiente manera:\n",
    "\n",
    "```python\n",
    "apply_pca = True\n",
    "use_product_category = True\n",
    "n_components_pca = 2\n",
    "features_selected = [\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\"]\n",
    "```\n",
    "\n",
    "Supongamos que sÃ³lo quisieramos usar \"customer_satisfaction\" y no usar PCA, podrÃ­amos ejecutar la funciÃ³n de la siguiente manera:\n",
    "\n",
    "```python\n",
    "apply_pca = False\n",
    "use_product_category = False\n",
    "n_components_pca = 2\n",
    "features_selected = [\"customer_satisfaction\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fd7eb0",
   "metadata": {},
   "source": [
    "ğŸ’» Por favor, elegÃ­ lo que queres hacer y ejecuta la celda de abajo ğŸ’»\n",
    "\n",
    "Para entender quÃ© hace la funciÃ³n, podes modificar cada una de las variables segÃºn se explica. Cada vez que ejecutes la celda, se procesarÃ¡n los datos de entrenamiento y se mostrarÃ¡ un pequeÃ±o resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "##caracterÃ­sticas de itneres [\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\"]\n",
    "apply_pca = True\n",
    "use_product_category = True\n",
    "n_components_pca = 2\n",
    "features_selected = [\"customer_satisfaction\"] ## posibles[\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\",\"packaging_width_cm\"]\n",
    "processSegmentedDataset(apply_pca,\n",
    "                        n_components_pca,\n",
    "                        use_product_category,\n",
    "                        features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380bdd8",
   "metadata": {},
   "source": [
    "### ğŸ“Š **<font color=\"#d6b302\">ğŸ’» 3.3 Prediciendo velocidad de venta ğŸ’»</font>**\n",
    "\n",
    "Ahora vamos a usar un Regresor Lineal para predecir el precio de venta a partir de los datos procesados.\n",
    "\n",
    "Al igual que antes, vas a poder decidir si usar PCA o no y si usar la variable categÃ³rica 'product_category' o no o bien elegir una o mÃ¡s caracterÃ­sticas de interÃ©s.\n",
    "\n",
    "LA funciÃ³n que usaremos para esto es `predictSalesVelocity()`. La misma nos arroja los siguientes resultados:\n",
    "\n",
    "1. Valor $R^2$ el cual indica quÃ© tan bien se ajusta el modelo a los datos. Un valor de $R^2$ cercano a 1 indica un buen ajuste, mientras que un valor cercano a 0 indica un mal ajuste.\n",
    "2. RMSE (Root Mean Squared Error) el cual mide la diferencia promedio entre los valores predichos por el modelo y los valores reales. Un valor de RMSE mÃ¡s bajo indica un mejor rendimiento del modelo.\n",
    "3. MAE (Mean Absolute Error) el cual mide la diferencia promedio absoluta entre los valores predichos por el modelo y los valores reales. Al igual que RMSE, un valor de MAE mÃ¡s bajo indica un mejor rendimiento del modelo.\n",
    "4. Una tabla con los primeros 5 valores reales, los predichos, su diferencia absoluta y el error porcentual.\n",
    "5. Un grÃ¡fico que muestra los valores reales vs los valores predichos en un scatter plot junto a una lÃ­nea roja que representa la lÃ­nea ideal donde los valores predichos son iguales a los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_pca = True\n",
    "use_product_category = True\n",
    "n_components_pca = 2\n",
    "features_selected = [\"packaging_width_cm\"] ## posibles[\"product_length_cm\",\"shelf_presence_score\",\"price_usd\",\"customer_satisfaction\",\"packaging_width_cm\"]\n",
    "\n",
    "predictSalesVelocity(apply_pca,\n",
    "                     n_components_pca,\n",
    "                     use_product_category,\n",
    "                     features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b94854",
   "metadata": {},
   "source": [
    "---â“---\n",
    "\n",
    "20. En base a las mÃ©tricas arrojadas por la funciÃ³n anterior Â¿QuÃ© tan bien funciona el modelo si se usa PCA y las variables categÃ³ricas?\n",
    "21. Â¿QuÃ© tan bien funciona el modelo si se usan por ejemplo las columnas \"price_usd\" y \"customer_satisfaction\"?\n",
    "22. Â¿QuÃ© tan bien funciona el modelo si sÃ³lo se usa la columna packaging_width_cm? Â¿Por quÃ© crees que arroja este desempeÃ±o? *(Obligatoria)*\n",
    "\n",
    "---â“---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e306029",
   "metadata": {},
   "source": [
    "## ğŸ“Š **<font color=\"#d6b302\">ğŸ’» 4. Clasificando categorÃ­as ğŸ’»</font>**\n",
    "\n",
    "En este ejercicio vamos a usar el mismo dataset del ejercicio 3, el cual recordemos tiene las siguientes features:\n",
    "\n",
    "- product_length_cm\n",
    "- packaging_width_cm\n",
    "- shelf_presence_score\n",
    "- sales_velocity\n",
    "- price_usd\n",
    "- product_category\n",
    "- customer_satisfaction\n",
    "\n",
    "Con este ejercicio se buscan dos cosas:\n",
    "\n",
    "1. Aplicar tÃ©cnicas de PCA y LDA para intentar mejorar la separabilidad de los datos y mejorar la clasificaciÃ³n.\n",
    "2. Demostrar, que a veces, no alcanza con tÃ©cnicas sencillas como hemos visto y necesitamos tÃ©cnicas mÃ¡s avanzadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
